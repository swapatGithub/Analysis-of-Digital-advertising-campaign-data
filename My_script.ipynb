{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model, decomposition, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load shipyard_final_script.py\n",
    "#function to count fold positions\t\n",
    "def cntFoldPos(values):\n",
    "    cnt0=0\n",
    "    cnt1=0\n",
    "    cnt2=0\n",
    "    for each in values:\n",
    "        if each==0:\n",
    "            cnt0=cnt0+1\n",
    "        elif each==1:\n",
    "            cnt1=cnt1+1\n",
    "        elif each==2:\n",
    "            cnt2=cnt2+1\n",
    "    return 0 if cnt0==max(cnt0,cnt1,cnt2) else 1 if cnt1==max(cnt0,cnt1,cnt2) else 2\n",
    "\n",
    "#function to identify viewed and converted and also those which are convereted but not in viewed dataset\n",
    "def viewedAndPV_converted(impr_data_pv_conv, impr_data_imp_noClicks):\n",
    "    list_pv_conv_viewed=[]\n",
    "    users_notViewedAds_converted=[]\n",
    "\n",
    "    for inde, seri in impr_data_pv_conv.iterrows():\n",
    "        if seri[15] in impr_data_imp_noClicks['user_id_64'].values:\n",
    "            for inde1, seri1 in impr_data_imp_noClicks[impr_data_imp_noClicks[\"user_id_64\"]==seri[15]].iterrows():\n",
    "                if seri[3]==seri1[3] and seri[2]==seri1[2] and seri[30]==seri1[30] and seri[29]==seri1[29]:           \n",
    "                    if inde1 not in list_pv_conv_viewed:\n",
    "                        list_pv_conv_viewed.append(inde1)\n",
    "        else:\n",
    "            if seri[15] not in users_notViewedAds_converted:\n",
    "                users_notViewedAds_converted.append(seri[15])\n",
    "\n",
    "    res_tuple=(list_pv_conv_viewed,users_notViewedAds_converted)\n",
    "    return res_tuple\n",
    "\n",
    "#function to identify Ads which are viewed and clicked \n",
    "def viewedAndClicked(impr_data_imp, impr_data_click):\n",
    "    events_viewed_and_clicked = []\n",
    "    for ind, val in impr_data_click[\"user_id_64\"].iteritems():\n",
    "        #print (ind, 'and', val)\n",
    "        if val in impr_data_imp[\"user_id_64\"].values: \n",
    "            height = impr_data_click[\"height\"].get(ind)\n",
    "            width = impr_data_click[\"width\"].get(ind)\n",
    "            C_id = impr_data_click[\"creative_id\"].get(ind)\n",
    "            camp_id = impr_data_click[\"campaign_id\"].get(ind)\n",
    "            for inde, seri in impr_data_imp[impr_data_imp[\"user_id_64\"]==val].iterrows():            \n",
    "                if height==seri[3] and width==seri[2] and C_id==seri[30] and camp_id==seri[29]:\n",
    "                    if inde not in events_viewed_and_clicked:\n",
    "                        events_viewed_and_clicked.append(inde) \n",
    "    return events_viewed_and_clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    impr_data = pd.read_csv(\"C:/Users/spawar5/Downloads/query_result/query_result.csv\")\n",
    "\n",
    "    #Segregating the data into 4 different event types\n",
    "    impr_data_imp = impr_data[impr_data[\"event_type\"]==\"imp\"]\n",
    "    impr_data_click = impr_data[impr_data[\"event_type\"]==\"click\"]\n",
    "    impr_data_pc_conv = impr_data[impr_data[\"event_type\"]==\"pc_conv\"]\n",
    "    impr_data_pv_conv = impr_data[impr_data[\"event_type\"]==\"pv_conv\"]\n",
    "\n",
    "    #Now, next line will check ads which are viewed and clicked\n",
    "    events_viewed_and_clicked = viewedAndClicked(impr_data_imp, impr_data_click) \n",
    "    #Number of events in impression which are clicked at some point in time by same user - 1765\n",
    "    \n",
    "    #Deleting these events from impression data as we need to analyse view data only\n",
    "    impr_data_imp_noClicks = impr_data_imp.drop(events_viewed_and_clicked) #dataframe has events which are viewed only and not clicked, count of rows - 1512780\n",
    "    impr_data_imp_withClicks = impr_data_imp.loc[events_viewed_and_clicked] #dataframe has events which are viewed and clicked\n",
    "    \n",
    "    #to get the records which are viewed and PV_converted and also those records which are converted without having viewed\n",
    "    tuple_viewed_PVConverted = viewedAndPV_converted(impr_data_pv_conv, impr_data_imp_noClicks)\n",
    "\n",
    "    list_pv_conv_viewed = tuple_viewed_PVConverted[0]\n",
    "    users_notViewedAds_converted = tuple_viewed_PVConverted[1]\n",
    "    \n",
    "    #Dataframe having ads which are viewed and converted\n",
    "    df_viewed_PV_conv = impr_data_imp_noClicks.loc[list_pv_conv_viewed]\n",
    "    #Dataframe having ads which are viewed but not converted\n",
    "    df_viewed_NOT_PVconv = impr_data_imp_noClicks.drop(list_pv_conv_viewed)\n",
    "\n",
    "    print('num of users viewed and converted - ',len(df_viewed_PV_conv.user_id_64.unique()), 'And number of users in converted only - ',len(users_notViewedAds_converted))\n",
    "    #Number of users in viewed and converted are 504 and number of users which are there in converted dataset only are 1128. This shows that digital campaign has not been successful #enough and people who already knew about the company have high chance of converting\n",
    "    \n",
    "    ####################Data mining approach to see which impression related factors have impact on customer conversion#######################\n",
    "    #Changing the granularity of records for usign data mining technique effectively. In new datasets a unique row is identified by userID, campaign ID and creating ID\n",
    "    user_ad_group_converted = df_viewed_PV_conv.groupby(['user_id_64','campaign_id','creative_id']) #num of user-Ad combination viewed and converted -  504\n",
    "    user_ad_group_notConverted = df_viewed_NOT_PVconv.groupby(['user_id_64','campaign_id','creative_id']) #num of user-Ad combination viewed and NOT converted -  917870\n",
    "\n",
    "    #Creating initial columns for two dataframes\n",
    "    uIDs = []\n",
    "    camp_ids = []\n",
    "    creat_ids = []\n",
    "    for each in list(user_ad_group_converted.indices.keys()):\n",
    "            uIDs.append(each[0])\n",
    "            camp_ids.append(each[1])\n",
    "            creat_ids.append(each[2])\n",
    "\n",
    "    uIDs1 = []\n",
    "    camp_ids1 = []\n",
    "    creat_ids1 = []\n",
    "    for each in list(user_ad_group_notConverted.indices.keys()):\n",
    "        uIDs1.append(each[0])\n",
    "        camp_ids1.append(each[1])\n",
    "        creat_ids1.append(each[2])\n",
    "\n",
    "    #New dataframes having unique row based on user, campaign and creative_ad\n",
    "    df_grouped_User_Ad = pd.DataFrame(data={'user_id_64':uIDs,'campaign_id':camp_ids,'creative_id':creat_ids})\n",
    "    df_grouped_UserAd_notConverted = pd.DataFrame(data={'user_id_64':uIDs1,'campaign_id':camp_ids1,'creative_id':creat_ids1})\t\t\n",
    "\n",
    "    #Creating a new columns by aggregating over existing columns based on groups of campaign, creative_ad and user and adding to the dataframes (feature engineering)\n",
    "    df_grouped_User_Ad['width'] = list(user_ad_group_converted.width.mean())\n",
    "    df_grouped_User_Ad['height'] = list(user_ad_group_converted.height.mean())\n",
    "    df_grouped_User_Ad['count_ad_viewed'] = list(user_ad_group_converted.datetime.count())\n",
    "    df_grouped_User_Ad['max_foldPosition'] = list(user_ad_group_converted.fold_position.apply(cntFoldPos))\n",
    "    df_grouped_User_Ad['avg_media_CPM'] = list(user_ad_group_converted.media_cost_dollars_cpm.mean())\n",
    "    df_grouped_User_Ad['avg_eap'] = list(user_ad_group_converted.eap.mean())\n",
    "    df_grouped_User_Ad['avg_creative_freq'] = list(user_ad_group_converted.creative_freq.mean())\n",
    "    df_grouped_User_Ad['time_ad_shown'] = list(user_ad_group_converted.creative_rec.max()- user_ad_group_converted.creative_rec.min())\n",
    "\n",
    "    df_grouped_UserAd_notConverted['width'] = list(user_ad_group_notConverted.width.mean())\n",
    "    df_grouped_UserAd_notConverted['height'] = list(user_ad_group_notConverted.height.mean())\n",
    "    df_grouped_UserAd_notConverted['count_ad_viewed'] = list(user_ad_group_notConverted.datetime.count())\n",
    "    df_grouped_UserAd_notConverted['max_foldPosition'] = list(user_ad_group_notConverted.fold_position.apply(cntFoldPos))\n",
    "    df_grouped_UserAd_notConverted['avg_media_CPM'] = list(user_ad_group_notConverted.media_cost_dollars_cpm.mean())\n",
    "    df_grouped_UserAd_notConverted['avg_eap'] = list(user_ad_group_notConverted.eap.mean())\n",
    "    df_grouped_UserAd_notConverted['avg_creative_freq'] = list(user_ad_group_notConverted.creative_freq.mean())\n",
    "    df_grouped_UserAd_notConverted['time_ad_shown'] = list(user_ad_group_notConverted.creative_rec.max()- user_ad_group_notConverted.creative_rec.min())\n",
    "\n",
    "    #creating a label variable\n",
    "    df_grouped_User_Ad['converted'] = 1\n",
    "    df_grouped_UserAd_notConverted['converted'] = 0\t\n",
    "\n",
    "    df_final = df_grouped_User_Ad.append(df_grouped_UserAd_notConverted)\n",
    "\n",
    "    #Shuffling the dataframe rows\n",
    "    df_final = df_final.iloc[np.random.permutation(len(df_final))]\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "    #Applying SMOTEEN algorithm for oversampling and undersampling\n",
    "    sm = SMOTEENN()\n",
    "    X_resampled, y_resampled = sm.fit_sample(df_final[df_final.columns[:-1]], df_final['converted'])\n",
    "\n",
    "    #print('Positive responses - ',y_resampled.nonzero()[0].size) -> 314908\n",
    "    #print('Negative responses - ',y_resampled.size-y_resampled.nonzero()[0].size) -> 917870\n",
    "\n",
    "    ###########Implementing a logistic model####################\n",
    "    #Removing first three columns as they are more like a combined ID field for each row\n",
    "    features_one = [each[3:] for each in X_resampled]\n",
    "    target = y_resampled\n",
    "    #70-30 training-test data split\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(features_one,target,random_state=1)\n",
    "    #Building a model\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "    my_logit_one = logistic.fit(Xtrain, Ytrain)\n",
    "\n",
    "    #model scoring with test data\n",
    "    print('Accuracy on test data ->',my_logit_one.score(Xtest,Ytest))\n",
    "    print('Model coefficients ->',my_logit_one.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of users viewed and converted -  504 And number of users in converted only -  1128\n",
      "0.815377769983\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
